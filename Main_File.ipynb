{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61a0492d-21cc-48c0-9744-7f6946e3cfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "pip install pandas selenium mysqlclient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da25468a-2680-40ac-b3e4-75d53c139aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import glob\n",
    "import mysql\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from sqlalchemy import create_engine\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e867c1a7-f46e-4957-9f01-88c05c73972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for scrapping the movie data from website\n",
    "def webscrapper(url):\n",
    "    # Initialize the WebDriver (Chrome in this case)\n",
    "    driver = webdriver.Chrome()\n",
    "\n",
    "    try:\n",
    "        # Open the IMDb page specified by the URL\n",
    "        driver.get(url)\n",
    "        # Maximize the browser window for better visibility\n",
    "        driver.maximize_window()\n",
    "        # Wait for 2 seconds to ensure the page is fully loaded\n",
    "        time.sleep(2)\n",
    "        # Print the title of the page to confirm it loaded correctly\n",
    "        print(driver.title)\n",
    "\n",
    "        # Attempt to click the \"Read More\" button to load all the data dynamically\n",
    "        while True:\n",
    "            try:\n",
    "                # Locate the \"Read More\" button using its XPath\n",
    "                element = driver.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/div[2]/div/span/button')\n",
    "                # Scroll the button into view if it's not currently visible\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", element)\n",
    "                # Wait for 1 second to ensure the button is visible\n",
    "                time.sleep(1)\n",
    "                # Click the \"Read More\" button to load more content\n",
    "                element.click()\n",
    "                # Print a message when the button is clicked\n",
    "                print(\"Clicked 'Read More' button.\")\n",
    "                # Wait for 1 second before trying again\n",
    "                time.sleep(1)\n",
    "            except NoSuchElementException:\n",
    "                # Exit loop if the \"Read More\" button is no longer available (all data is loaded)\n",
    "                print(\"No 'Read More' button found. All data loaded.\")\n",
    "                break\n",
    "            except ElementClickInterceptedException:\n",
    "                # If the button is blocked by another element, retry after a short delay\n",
    "                print(\"Button is blocked by another element. Retrying...\")\n",
    "                time.sleep(2)\n",
    "            except TimeoutException:\n",
    "                # Handle cases where the operation times out and retry\n",
    "                print(\"Operation timed out. Retrying...\")\n",
    "                time.sleep(2)\n",
    "            except Exception as e:\n",
    "                # Catch any other unexpected errors\n",
    "                print(f\"Unexpected error: {e}\")\n",
    "                break\n",
    "\n",
    "        print(\"Successfully retrieved all the data.\")\n",
    "\n",
    "        # Initialize a dictionary to store movie data categorized by genre\n",
    "        genre_data = {}\n",
    "\n",
    "        # Locate all movie items on the page\n",
    "        movies = driver.find_elements(By.XPATH,'//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[2]/div[2]/ul/li')\n",
    "        \n",
    "        # Extract details for each movie\n",
    "        for movie in movies:\n",
    "            try:\n",
    "                # Extract the movie name, ensuring it splits correctly to remove unnecessary text\n",
    "                name = movie.find_element(By.CSS_SELECTOR, 'h3[class=\"ipc-title__text\"]').text.split(\". \", 1)[1]\n",
    "\n",
    "                # Attempt to extract the genre of the movie, using a fallback if not found\n",
    "                try:\n",
    "                    genre = movie.find_element(By.XPATH, '//*[@id=\"__next\"]/main/div[2]/div[3]/section/section/div/section/section/div[2]/div/section/div[1]/div/div/div[2]/button[3]/span').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    genre = \"Unknown\" # If no genre is found, mark it as \"Unknown\"\n",
    "\n",
    "                # Extract movie rating, handling cases where it's missing\n",
    "                try:\n",
    "                    rating = movie.find_element(By.CSS_SELECTOR, \"span[class='ipc-rating-star--rating']\").text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    rating = \"N/A\" # If no votes are found, mark it as \"N/A\"\n",
    "\n",
    "                # Extract vote count, formatting it correctly and handling missing data\n",
    "                try:\n",
    "                    votes = movie.find_element(By.CSS_SELECTOR, \"span[class='ipc-rating-star--voteCount']\").text.replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "                except NoSuchElementException:\n",
    "                    votes = \"N/A\" # If no votes are found, mark it as \"N/A\"\n",
    "\n",
    "                # Extract movie duration, using a fallback if not found\n",
    "                try:\n",
    "                    duration = movie.find_element(By.XPATH, './div/div/div/div[1]/div[2]/div[2]/span[2]').text.strip()\n",
    "                except NoSuchElementException:\n",
    "                    duration = \"N/A\" # If no votes are found, mark it as \"N/A\"\n",
    "\n",
    "                # Split the genre(s) into a list and store movie data in a dictionary under each genre\n",
    "                for g in genre.split(\", \"):\n",
    "                    if g not in genre_data:\n",
    "                        genre_data[g] = []  # Initialize an empty list for new genres\n",
    "                    # Append movie details to the respective genre's list\n",
    "                    genre_data[g].append({\n",
    "                        \"Movie Name\": name,\n",
    "                        \"Rating\": rating,\n",
    "                        \"Votes\": votes,\n",
    "                        \"Duration\": duration,\n",
    "                        \"Genre\": genre\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                # Handle errors that may occur while processing individual movies\n",
    "                print(f\"Error processing movie: {e}\")\n",
    "\n",
    "        return genre_data  # Return the dictionary containing movie data organized by genre\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle errors that occur while retrieving or processing the page data\n",
    "        print(f\"Error retrieving movie list: {e}\")\n",
    "        return {}  # Return an empty dictionary if an error occurs\n",
    "\n",
    "    finally:\n",
    "        driver.quit()  # Quit the WebDriver when finished, ensuring resources are released\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6189590-69a8-4aa1-b2e1-2bef25e8e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save data to CSV files\n",
    "\n",
    "def genre_dataset(genre_data):\n",
    "    # Create a new folder to save the CSV files, if it doesn't already exist\n",
    "    output_dir = \"IMDB_2024_Genres_Data\"\n",
    "    \n",
    "    # Use os.makedirs to create the directory, with 'exist_ok=True' to avoid error if folder already exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Loop through the genre_data dictionary (which holds movie data categorized by genre)\n",
    "    for genre, movies in genre_data.items():\n",
    "        # Convert the list of movies (which is in dictionary format) to a pandas DataFrame\n",
    "        df = pd.DataFrame(movies)\n",
    "        \n",
    "        # Create the file name by joining the output directory path with the genre name and .csv extension\n",
    "        file_name = os.path.join(output_dir, f\"{genre}.csv\")\n",
    "        \n",
    "       # Save the DataFrame as a CSV file in the specified location, excluding the index column\n",
    "        df.to_csv(file_name, index=False)\n",
    "        \n",
    "        # Print a confirmation message with the name of the genre and file that was created\n",
    "        print (f\"Saved data for genre '{genre}' to '{file_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99d9ca7a-84d0-46fa-80c0-635c6132b3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# List of IMDb genre-specific movie URLs for the year 2024\n",
    "genre_urls = [\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=news\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=talk-show\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=game-show\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=war\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=western\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=action\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=comedy\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=drama\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=crime\",\n",
    "    \"https://www.imdb.com/search/title/?title_type=feature&release_date=2024-01-01,2024-12-31&genres=family\"\n",
    "]\n",
    "\n",
    "# Loop through each genre URL and scrape data for that genre\n",
    "for genre_url in genre_urls:\n",
    "    try:\n",
    "        # Display the current URL being processed\n",
    "        print(f\"URL Processing: {genre_url}\")\n",
    "        \n",
    "        # Call the webscrapper function to scrape movie data for the given genre URL\n",
    "        movies_by_genre = webscrapper(genre_url)\n",
    "\n",
    "        # Check and print the data type returned for debugging\n",
    "        print(f\"Data type returned: {type(movies_by_genre)}\")  # Debugging check\n",
    "\n",
    "        # Check if the data returned is a valid non-empty dictionary\n",
    "        if movies_by_genre and isinstance(movies_by_genre, dict):  \n",
    "            try:\n",
    "                # Call the genre_dataset function to save the data to CSV files\n",
    "                genre_dataset(movies_by_genre)\n",
    "                print(f\"Successfully stored\")\n",
    "            except Exception as dataset_error:\n",
    "                # Handle errors during the saving process\n",
    "                print(f\"Error saving dataset for {genre_url}: {dataset_error}\")\n",
    "        else:\n",
    "            # If no valid data is retrieved, skip processing for this URL\n",
    "            print(f\"Skipping {genre_url} as no valid data was retrieved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during the scraping process for this URL\n",
    "        print(f\"Error processing {genre_url}: {e}\")\n",
    "\n",
    "# Print a success message when all URLs are processed\n",
    "print('✅ Successfully completed processing all genres!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0a94fd9-8f98-4ab1-90c9-d7cb4b12ff41",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use glob to find all CSV files in the folder\n",
    "glob.glob('IMDB_2024_Genres_data\\\\*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37e7acb1-6813-4d79-9844-bf16f7f02e72",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use glob to find all CSV files in the folder and combine them into a single DataFrame\n",
    "df = pd.concat([pd.read_csv(one_file) for one_file in glob.glob('IMDB_2024_Genres_data\\\\*.csv')],ignore_index=True)\n",
    "\n",
    "# Reset the index of the combined DataFrame to ensure it starts from 0 and is sequential\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Save the combined DataFrame as a new CSV file called 'genre_combined_df.csv'\n",
    "df.to_csv('genre_combined_df.csv', index=False)\n",
    "\n",
    "# Print the DataFrame to verify the rows (12144 rows as mentioned)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1430c451-ea95-4ba9-84eb-7555e9dd9ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Check the detailed memory usage of the DataFrame using this method.\n",
    "df.info()   #474.5KB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e390d26b-6cb0-46d3-954b-bd2cb30aadea",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the combined CSV file into a new DataFrame\n",
    "new_df = pd.read_csv('genre_combined_df.csv')\n",
    "\n",
    "# Drop rows with missing values and reset the index\n",
    "new_df.dropna(inplace = True,ignore_index=True)\n",
    "\n",
    "# Drop duplicate rows to ensure unique records\n",
    "new_df.drop_duplicates(inplace = True)\n",
    "\n",
    "# Display the first 5 rows of the cleaned DataFrame\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5203a82-736e-4c9b-ab0c-afb4a15a6248",
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning\n",
    "\n",
    "# Replace 'K' with 'e3' and 'M' with 'e6' to denote scientific notation\n",
    "new_df['Votes'] = new_df['Votes'].str.replace('K','e3').str.replace('M','e6')\n",
    "\n",
    "# Display the entire \"Votes\" column as a string to view the changes\n",
    "new_df[\"Votes\"].to_string()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c631170-1dbc-4af3-954d-575a6fde64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hours and minutes using string methods\n",
    "Hours = new_df[\"Duration\"].str.extract(r'(\\d+)h').fillna(0).astype(int)\n",
    "Minutes = new_df[\"Duration\"].str.extract(r'(\\d+)m').fillna(0).astype(int)\n",
    "\n",
    "# Changing Duration column into Minutes\n",
    "new_df[\"Duration\"] = (Hours * 60) + Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea2be5cf-4a2e-4cd4-8733-5ce9e3814581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the cleaned dataset to a CSV file for future use or database upload\n",
    "new_df.to_csv('genre_df_cleaned.csv', index=False)\n",
    "\n",
    "# The dataset is now ready for uploading to the database or further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6695afa-b9f5-4775-8026-d6b9a3cbfd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing a connection to the MySQL database using SQLAlchemy engine\n",
    "engine = create_engine(\"mysql+mysqldb://root:tony123@localhost:3306/imdb_2024_genres\")  # root@localhost:3306\n",
    "\n",
    "# Connecting to the database engine\n",
    "conn = engine.connect()\n",
    "\n",
    "# Reading the cleaned dataset from CSV file\n",
    "data =pd.read_csv('genre_df_cleaned.csv')\n",
    "\n",
    "# Pushing the dataset into the 'movie data' table in the database\n",
    "# 'replace' ensures the table is replaced if it already exists\n",
    "data.to_sql('movie_data', engine, index = False, if_exists = 'replace')\n",
    "\n",
    "# Closing the connection after the operation is complete\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ef89e6-a974-4998-9128-587e3dccf74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
